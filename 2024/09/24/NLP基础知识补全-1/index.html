<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>NLP基础知识补全-1 | 一世逍遥的博客</title><meta name="author" content="LiSheng"><meta name="copyright" content="LiSheng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="NLP基础知识补全 本文档旨在汇集NLP中一些常见的基础知识。主要包含损失函数、优化器、微调方法、Normlization Layer、位置编码、激活函数、Attention实现、量化模型、常见大模型结构几部分。 损失函数 这部分主要参考知乎文章：损失函数(Loss Function)（https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;261059231） 1. 什么是损失函数？ 一言以蔽">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP基础知识补全-1">
<meta property="og:url" content="https://lisheng2001.github.io/2024/09/24/NLP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%A8-1/index.html">
<meta property="og:site_name" content="一世逍遥的博客">
<meta property="og:description" content="NLP基础知识补全 本文档旨在汇集NLP中一些常见的基础知识。主要包含损失函数、优化器、微调方法、Normlization Layer、位置编码、激活函数、Attention实现、量化模型、常见大模型结构几部分。 损失函数 这部分主要参考知乎文章：损失函数(Loss Function)（https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;261059231） 1. 什么是损失函数？ 一言以蔽">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lisheng2001.github.io/images/avatar.webp">
<meta property="article:published_time" content="2024-09-24T03:57:59.000Z">
<meta property="article:modified_time" content="2025-03-28T15:16:42.428Z">
<meta property="article:author" content="LiSheng">
<meta property="article:tag" content="自然语言处理">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lisheng2001.github.io/images/avatar.webp"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://lisheng2001.github.io/2024/09/24/NLP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%A8-1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'NLP基础知识补全-1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-03-28 23:16:42'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/avatar.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">51</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">71</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="一世逍遥的博客"><span class="site-name">一世逍遥的博客</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">NLP基础知识补全-1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-09-24T03:57:59.000Z" title="发表于 2024-09-24 11:57:59">2024-09-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-28T15:16:42.428Z" title="更新于 2025-03-28 23:16:42">2025-03-28</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="NLP基础知识补全-1"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h1 id="nlp基础知识补全">NLP基础知识补全</h1>
<p>本文档旨在汇集NLP中一些常见的基础知识。主要包含损失函数、优化器、微调方法、Normlization
Layer、位置编码、激活函数、Attention实现、量化模型、常见大模型结构几部分。</p>
<h2 id="损失函数">损失函数</h2>
<p>这部分主要参考知乎文章：损失函数(Loss
Function)（https://zhuanlan.zhihu.com/p/261059231）</p>
<h3 id="什么是损失函数">1. 什么是损失函数？</h3>
<p>一言以蔽之，损失函数（loss
function）就是用来度量模型的预测值f(x)与真实值Y的差异程度的运算函数，它是一个非负实值函数，通常使用L(Y,
f(x))来表示，损失函数越小，模型的鲁棒性就越好。</p>
<h3 id="为什么使用损失函数">2. 为什么使用损失函数？</h3>
<p>损失函数使用主要是在模型的训练阶段，每个批次的训练数据送入模型后，通过前向传播输出预测值，然后损失函数会计算出预测值和真实值之间的差异值，也就是损失值。得到损失值之后，模型通过反向传播去更新各个参数，来降低真实值与预测值之间的损失，使得模型生成的预测值往真实值方向靠拢，从而达到学习的目的。</p>
<h3 id="有哪些损失函数">3. 有哪些损失函数？</h3>
<h4 id="基于距离度量的损失函数">3.1 基于距离度量的损失函数</h4>
<p>基于距离度量的损失函数通常将输入数据映射到基于距离度量的特征空间上，如欧氏空间、汉明空间等，将映射后的样本看作空间上的点，采用合适的损失函数度量特征空间上样本真实值和模型预测值之间的距离。特征空间上两个点的距离越小，模型的预测性能越好。</p>
<h5 id="均方误差损失函数mse">3.1.1 均方误差损失函数（MSE）</h5>
<p>公式： <span
class="math inline">\(L(Y|f(x))=\frac{1}{n}\sum_{i=1}^{N}{(Y_{i}-f(x_{i}))^{2}}\)</span></p>
<p>在回归问题中，均方误差损失函数用于度量样本点到回归曲线的距离，通过最小化平方损失使样本点可以更好地拟合回归曲线。均方误差损失函数（MSE）的值越小，表示预测模型描述的样本数据具有越好的精确度。由于无参数、计算成本低和具有明确物理意义等优点，MSE已成为一种优秀的距离度量方法。尽管MSE在图像和语音处理方面表现较弱，但它仍是评价信号质量的标准，在回归问题中，MSE常被作为模型的经验损失或算法的性能指标。</p>
<p>代码实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"># 自定义实现</span><br><span class="line">def MSELoss(x:list,y:list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x:list，代表模型预测的一组数据</span><br><span class="line">    y:list，代表真实样本对应的一组数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    assert len(x)==len(y)</span><br><span class="line">    x=np.array(x)</span><br><span class="line">    y=np.array(y)</span><br><span class="line">    loss=np.sum(np.square(x - y)) / len(x)</span><br><span class="line">    return loss</span><br><span class="line"></span><br><span class="line">#计算过程举例</span><br><span class="line">x=[1,2]</span><br><span class="line">y=[0,1]</span><br><span class="line">loss=（（1-0）**2 + （2-1）**2）÷2=（1+1）÷2=1</span><br><span class="line"></span><br><span class="line"># Tensorflow2.0版</span><br><span class="line">y_true=tf.convert_to_tensor(y)</span><br><span class="line">y_pred=tf.convert_to_tensor(x)</span><br><span class="line">mse_loss = tf.keras.losses.MSE(y_true, y_pred) # y_true, y_pred都是张量格式</span><br><span class="line"></span><br><span class="line"># pytorch版本</span><br><span class="line">y_true=torch.tensor(y)</span><br><span class="line">y_pred=torch.tensor(x)</span><br><span class="line">mse_fc = torch.nn.MSELoss(y_true, y_pred)</span><br><span class="line">mse_loss = mse_fc(x,y)</span><br></pre></td></tr></table></figure>
<h5 id="l2损失函数">3.1.2 L2损失函数</h5>
<p>L2损失函数： <span
class="math inline">\(L(Y|f(x))=\sqrt{\frac{1}{n}\sum_{i=1}^{N}{(Y_{i}-f(x_{i}))^{2}}}\)</span></p>
<p>L2损失又被称为欧氏距离，是一种常用的距离度量方法，通常用于度量数据点之间的相似度。由于L2损失具有凸性和可微性，且在独立、同分布的高斯噪声情况下，它能提供最大似然估计，使得它成为回归问题、模式识别、图像处理中最常使用的损失函数。</p>
<p>代码实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"># 自定义实现</span><br><span class="line">def L2Loss(x:list,y:list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x:list，代表模型预测的一组数据</span><br><span class="line">    y:list，代表真实样本对应的一组数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    assert len(x)==len(y)</span><br><span class="line">    x=np.array(x)</span><br><span class="line">    y=np.array(y)</span><br><span class="line">    loss=np.sqrt(np.sum(np.square(x - y)) / len(x))</span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>
<h5 id="l1损失函数">3.1.3 L1损失函数</h5>
<p>L1损失函数： <span
class="math inline">\(L(Y|f(x))=\sum_{i=1}^{N}{|Y_{i}-f(x_{i})|}\)</span></p>
<p>L1损失又称为曼哈顿距离，表示残差的绝对值之和。L1损失函数对离群点有很好的鲁棒性，但它在残差为零处却不可导。另一个缺点是更新的梯度始终相同，也就是说，即使很小的损失值，梯度也很大，这样不利于模型的收敛。针对它的收敛问题，一般的解决办法是在优化算法中使用变化的学习率，在损失接近最小值时降低学习率。</p>
<p>代码实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"># 自定义实现</span><br><span class="line">def L1Loss(x:list,y:list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    x:list，代表模型预测的一组数据</span><br><span class="line">    y:list，代表真实样本对应的一组数据</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    assert len(x)==len(y)</span><br><span class="line">    x=np.array(x)</span><br><span class="line">    y=np.array(y)</span><br><span class="line">    loss=np.sum(np.abs(x - y)) / len(x)</span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>
<h4 id="基于概率分布度量的损失函数">3.2 基于概率分布度量的损失函数</h4>
<p>基于概率分布度量的损失函数是将样本间的相似性转化为随机事件出现的可能性，即通过度量样本的真实分布与它估计的分布之间的距离，判断两者的相似度，一般用于涉及概率分布或预测类别出现的概率的应用问题中，在分类问题中尤为常用。</p>
<h5 id="kl散度函数相对熵">3.2.1 KL散度函数（相对熵）</h5>
<p>公式： <span
class="math inline">\(L(Y|f(x))=\sum_{i=1}^{n}{Y_{i}\times
log(\frac{Y_{i}}{f(x_{i})})}\)</span></p>
<p>公式中Y代表真实值，f(x)代表预测值。 KL散度（ Kullback-Leibler
divergence）也被称为相对熵，是一种非对称度量方法，常用于度量两个概率分布之间的距离。KL散度也可以衡量两个随机分布之间的距离，两个随机分布的相似度越高的，它们的KL散度越小，当两个随机分布的差别增大时，它们的KL散度也会增大，因此KL散度可以用于比较文本标签或图像的相似性。基于KL散度的演化损失函数有JS散度函数。JS散度也称JS距离，用于衡量两个概率分布之间的相似度，它是基于KL散度的一种变形，消除了KL散度非对称的问题，与KL散度相比，它使得相似度判别更加准确。</p>
<pre><code>相对熵是恒大于等于0的。当且仅当两分布相同时，相对熵等于0。</code></pre>
<p>代码实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def kl_loss(y_true:list,y_pred:list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    y_true,y_pred，分别是两个概率分布</span><br><span class="line">    比如：px=[0.1,0.2,0.8]</span><br><span class="line">          py=[0.3,0.3,0.4]</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    assert len(y_true)==len(y_pred)</span><br><span class="line">    KL=0</span><br><span class="line">    for y,fx in zip(y_true,y_pred):</span><br><span class="line">        KL+=y*np.log(y/fx)</span><br><span class="line">    return KL</span><br></pre></td></tr></table></figure>
<h5 id="交叉熵损失">3.2.2 交叉熵损失</h5>
<p>公式： <span class="math inline">\(L(Y|f(x))=-\sum_{i=1}^{N}{Y_{i}log
f(x_{i})}\)</span></p>
<p>交叉熵是信息论中的一个概念，最初用于估算平均编码长度，引入机器学习后，用于评估当前训练得到的概率分布与真实分布的差异情况。为了使神经网络的每一层输出从线性组合转为非线性逼近，以提高模型的预测精度，在以交叉熵为损失函数的神经网络模型中一般选用tanh、sigmoid、softmax或ReLU作为激活函数。</p>
<p>交叉熵损失函数刻画了实际输出概率与期望输出概率之间的相似度，也就是交叉熵的值越小，两个概率分布就越接近，特别是在正负样本不均衡的分类问题中，常用交叉熵作为损失函数。目前，交叉熵损失函数是卷积神经网络中最常使用的分类损失函数，它可以有效避免梯度消散。在二分类情况下也叫做对数损失函数。</p>
<p>代码实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def CrossEntropy_loss(y_true:list,y_pred:list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    y_true,y_pred，分别是两个概率分布</span><br><span class="line">    比如：px=[0.1,0.2,0.8]</span><br><span class="line">          py=[0.3,0.3,0.4]</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    assert len(y_true)==len(y_pred)</span><br><span class="line">    loss=0</span><br><span class="line">    for y,fx in zip(y_true,y_pred):</span><br><span class="line">        loss+=-y * np.log(fx)</span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>
<p>当正负样本不均衡的时候，通常会在交叉熵损失函数类别前面加个参数α</p>
<p><span class="math display">\[CE =  \begin{cases}     -\alpha log(p)
&amp; \text{   y = 1}  \\    -(1-\alpha )log(1-p)       &amp; \text{ y =
0}  \end{cases}\\\]</span></p>
<h5 id="softmax损失函数">3.2.3 softmax损失函数</h5>
<p>公式： <span
class="math inline">\(L(Y|f(x))=-\frac{1}{n}\sum_{i=1}^{n}{log\frac{e^{f_{Y_{i}}}}{\sum_{j=1}^{c}{e^{f_{j}}}}}\)</span></p>
<p>从标准形式上看，softmax损失函数应归到对数损失的范畴，在监督学习中，由于它被广泛使用，所以单独形成一个类别。softmax损失函数本质上是逻辑回归模型在多分类任务上的一种延伸，常作为CNN模型的损失函数。softmax损失函数的本质是将一个k维的任意实数向量x映射成另一个k维的实数向量，其中，输出向量中的每个元素的取值范围都是(0,1)，即softmax损失函数输出每个类别的预测概率。由于softmax损失函数具有类间可分性，被广泛用于分类、分割、人脸识别、图像自动标注和人脸验证等问题中，其特点是类间距离的优化效果非常好，但类内距离的优化效果比较差。</p>
<p>softmax损失函数具有类间可分性，在多分类和图像标注问题中，常用它解决特征分离问题。在基于卷积神经网络的分类问题中，一般使用softmax损失函数作为损失函数，但是softmax损失函数学习到的特征不具有足够的区分性，因此它常与对比损失或中心损失组合使用，以增强区分能力。</p>
<p>代码实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def softmax(x):</span><br><span class="line">    x_exp = np.exp(x)</span><br><span class="line">    x_sum = np.sum(x_exp, axis=1, keepdims=True)</span><br><span class="line">    s = x_exp / x_sum</span><br><span class="line">    return s</span><br><span class="line"></span><br><span class="line"># Tensorflow2.0版</span><br><span class="line">softmax_fc = tf.keras.activations.softmax(x)</span><br><span class="line"># pytorch版</span><br><span class="line">softmax_fc = torch.nn.Softmax()</span><br><span class="line">output = softmax_fc(x)</span><br></pre></td></tr></table></figure>
<h5 id="focal-loss">3.2.4 Focal loss</h5>
<p>focal
loss的引入主要是为了解决难易样本不均衡的问题，注意有区别于正负样本不均衡的问题。难易样本分为四个类型：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>难</th>
<th>易</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>正</td>
<td>正难</td>
<td>正易</td>
</tr>
<tr class="even">
<td>负</td>
<td>负难</td>
<td>负易</td>
</tr>
</tbody>
</table>
<p>易分样本虽然损失很低，但是数量太多，对模型的效果提升贡献很小，模型应该重点关注那些难分样本，因此需要把置信度高的损失再降低一些</p>
<p><span class="math inline">\(FE = \begin{cases} -\alpha(1-p)^{\gamma}
log(p) &amp; \text{   y = 1} \\ -(1-\alpha )p^{\gamma} log(1-p) &amp;
\text{ y = 0} \end{cases}\\\)</span></p>
<h3 id="如何选择损失函数">4. 如何选择损失函数？</h3>
<p>通常情况下，损失函数的选取应从以下方面考虑：</p>
<p>（1）
选择最能表达数据的主要特征来构建基于距离或基于概率分布度量的特征空间。</p>
<p>（2）选择合理的特征归一化方法，使特征向量转换后仍能保持原来数据的核心内容。</p>
<p>（3）选取合理的损失函数，在实验的基础上，依据损失不断调整模型的参数，使其尽可能实现类别区分。</p>
<p>（4）合理组合不同的损失函数，发挥每个损失函数的优点，使它们能更好地度量样本间的相似性。</p>
<p>（5）将数据的主要特征嵌入损失函数，提升基于特定任务的模型预测精确度。</p>
<h2 id="优化器">优化器</h2>
<p>这部分主要参考知乎文章：[深度学基础]优化器算法SGD,AdaGrad,RMSprop,Adam（https://zhuanlan.zhihu.com/p/618265040），以及知乎文章：Adam和AdamW（https://zhuanlan.zhihu.com/p/643452086）。主要包含SGD（随机梯度下降）、RMSProp、Adam和AdamW。</p>
<p>本文首先介绍基础梯度下降法，然后介绍对SGD的改进方法：动量法、AdaGrad、RMSprop以及Adam。本专栏的文章都是本人找工作时根据面试经历和网络资料整理，因此更偏向于要点罗列的形式。由于是为了应付面试，内容略显肤浅，且本人水平有限，若想在学术科研的层面有更深入的理解，还请参考相关论文以及大佬的文章。</p>
<h3 id="梯度下降法">梯度下降法</h3>
<p>梯度是一个向量，表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向变化最快。梯度下降的主要思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降[这个意思是使得待优化函数例如Loss减小最快的参数更新方向]方向，所以也被称为”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。当目标函数是凸函数时，梯度下降的解时全局最优。但一般情况下，其解不保证全局最优。梯度下降原理推导(这个链接里的<a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/82757193">马东什么：梯度下降法和一阶泰勒展开的关系</a>，很清晰)，主要是理解为什么负梯度时下降最快的方向，为什么会有学习率这个东西，本质是对损失函数进行泰勒展开得到的。</p>
<p>在机器学习种，基于基本的梯度下降法，发展出了3种具体的梯度下降方法，分别为
BGD(Batch Gradient Descent批量梯度下降法)，SGD， mini-batch GD</p>
<p><strong>批量梯度下降法（Batch Gradient Desceent,
BGD）：</strong>具体做法也就是在更新参数时使用所有的样本来进行更新。
这样一来每迭代一步，都要用到训练集所有的数据，如果数据量很大，那么可想而知这种方法的迭代速度会很慢。</p>
<p><strong>随机梯度下降（Stochastic Gradient Descent,
SGD）：</strong>每次迭代只用到了一个样本，在样本量很大的情况下，常见的情况是只用到了其中一部分样本数据即可迭代到最优解。因此随机梯度下降比批量梯度下降在计算量上会大大减少。SGD有一个缺点是，其噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。而且SGD因为每次都是使用一个样本进行迭代，因此最终求得的最优解往往不是全局最优解，而只是局部最优解。但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。</p>
<p><strong>小批量梯度下降（Mini-batch Gradient
Descent）：</strong>小批量梯度下降法是批量梯度下降法和随机梯度下降法的折衷，也就是对于m个样本，我们采用
x个样子来迭代，1&lt;x&lt;m 。</p>
<h3 id="指数移动平均">指数移动平均</h3>
<p>为了方便后续对SGD的改进方法的介绍，先介绍指数移动平均的概念。指数移动平均是以指数式递减加权的移动平均。
各数值的加权影响力随时间而指数式递减，越近期的数据加权影响力越重，但较旧的数据也给予一定的加权值。</p>
<p>计算公式为： $v_t=v_{t-1}+(1-)_t $</p>
<p>优点：当想要计算均值的时候，不用保留所有时刻的值。随着时间推移，遥远过去的历史的影响会越来越小</p>
<h3 id="动量法momentum">动量法(Momentum)</h3>
<p><strong>算法思想：</strong>参数更新方向不仅由当前的梯度决定，也与此前累积的梯度方向有关。将过去梯度的指数移动平均称为动量。当前参数的更新值由动量和当前梯度两部分确定。在当前梯度方向发生改变时(震荡通常发生在梯度方向改变的时候)，动量能够降低参数更新的速度，从而减少震荡；当前梯度方向与之前的梯度方向相同时，动量能够加速参数更新，从而加速收敛。</p>
<p><strong>参数更新：</strong></p>
<p><span class="math inline">\(m_{t+1}=\gamma m_t +
(1-\gamma)\nabla_{\theta}J(\theta)\)</span></p>
<p><span
class="math inline">\(\theta_{t+1}=\theta_{t}-m_{t+1}\)</span></p>
<p>参数 <span class="math inline">\(\gamma\)</span>
决定了之前的梯度的贡献衰减的速度。当 <span
class="math inline">\(\gamma=0\)</span> 时，动量法就是SGD。</p>
<p><img src="/images/v2-0b9dc4f97a0a958509ec52d6f09ffbc3_b.jpg" /></p>
<p><strong>算法流程：</strong></p>
<p><img src="/images/v2-76ad97169635f2d3b6227b45f453ef11_b.jpg" /></p>
<h3 id="adagrad">AdaGrad</h3>
<p><strong>算法思想：</strong>之前的SGD、动量法对每个参数都使用相同的学习率，AdaGrad对不同的参数动态采取不同的学习率。对于每个参数，其学习率为全局学习率除以该参数历史梯度平方和的平方根。在参数空间更为平缓的方向，会取得更大的进步（因为平缓，所以历史梯度平方和较小，对应学习下降的幅度较小），并且能够使得陡峭的方向变得平缓，从而加快训练速度。缺点：由于累计梯度平方和，训练中后期，分母越来越大，导致学习率很快会接近0。</p>
<p><strong>参数更新：</strong></p>
<p><span class="math inline">\(s_{t+1}=s_t+\nabla_{\theta}J(\theta)\odot
\nabla_{\theta}J(\theta)\)</span></p>
<p><span
class="math inline">\(\theta_{t+1}=\theta_{t}-\frac{\alpha}{\sqrt{s_{t+1}+\varepsilon}}\odot\nabla_{\theta}J(\theta)\)</span></p>
<p><span class="math inline">\(\odot\)</span>
表示Hadamard乘积(向量对应位置的元素相乘)， <span
class="math inline">\(\alpha\)</span> 是全局学习率。</p>
<p><strong>算法流程：</strong></p>
<p><img src="/images/v2-bbf205287c7401cc0cb80404a086fc5d_b.jpg" /></p>
<h3 id="rmsprop">RMSprop</h3>
<p><strong>基本思想：</strong>RMSprop也是一种自适应学习率的方法，是在AdaGrad上的改进。AdaGrad会累计之前所有的梯度平方，而RMSprop采用的是指数加权移动平均，能够丢弃掉遥远过去的历史梯度平方，从而缓解AdaGrad学习率随迭代次数下降过快的问题。</p>
<p><strong>参数更新：</strong></p>
<p><span class="math inline">\(r_{t+1}=\gamma
r_t+(1-\gamma)\nabla_{\theta}J(\theta)\odot\nabla_{\theta}J(\theta)\)</span></p>
<p><span
class="math inline">\(\theta_{t+1}=\theta_{t}-\frac{\alpha}{\sqrt{r_{t+1}+\epsilon}}\odot\nabla_{\theta}J(\theta)\)</span></p>
<p><strong>算法流程：</strong></p>
<p><img src="/images/v2-d07eeb18083db6890eed0d378f9b856f_b.jpg" /></p>
<h3 id="adam">Adam</h3>
<p><strong>基本思想：</strong>也是一种自适应学习率的方法，可以看作是结合了RMSProp和动量法。Adam同时具备Momentum和RMSprop的优点。一是记录了过去的梯度，使用过去的累积梯度(动量)和当前梯度共同确定当前参数的更新量，可以减小震荡，加速收敛。而是使用梯度平和的累积值来动态调整学习率。</p>
<p><span
class="math inline">\(m_{t+1}=\beta_1m_t+(1-\beta_1)\nabla_{\theta}J(\theta)\)</span></p>
<p><span
class="math inline">\(r_{t+1}=\beta_2r_t+(1-\beta_2)\nabla_{\theta}J(\theta)\odot\nabla_{\theta}J(\theta)\)</span></p>
<p><span
class="math inline">\(\hat{m}_{t+1}=\frac{m_{t+1}}{1-\beta_1^{t}}，
\hat{r}_{t+1}=\frac{r_t}{1-\beta_2^t}\)</span></p>
<p><span
class="math inline">\(\theta_{t+1}=\theta_t-\frac{\alpha}{\sqrt{r_{t+1}}+\epsilon}m_{t+1}\)</span></p>
<p><strong>算法流程：</strong></p>
<p><img src="/images/v2-30073e5f49ef891d3b0c5010292e8fd2_b.jpg" /></p>
<p>Adam详细参数说明可以参见<a
target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_36618660/article/details/100026261">https://blog.csdn.net/sinat_36618660/article/details/100026261</a></p>
<h3 id="adamw">AdamW</h3>
<p>AdamW相对与Adam的改动十分简单，其将权重衰减项从梯度的计算中拿出来直接加在了最后的权重更新步骤上（图1，式12）。其提出的动机在于：原先Adam的实现中如果采用了L2权重衰减，则相应的权重衰减项会被直接加在loss里，从而导致动量的一阶与二阶滑动平均均考虑了该权重衰减项（图1.
式6），而这影响了Adam的优化效果，而将权重衰减与梯度的计算进行解耦能够显著提升Adam的效果。目前，AdamW现在已经成为transformer训练中的默认优化器了。</p>
<figure>
<img src="/images/v2-b2bb37449901505a1f47ea7b22d2f52b_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>关于显存占用：Adam和AdamW在反向传播时需要维护的变量分别为原始参数<span
class="math inline">\(\theta_t\)</span>，梯度<span
class="math inline">\(g_t\)</span>，动量<span
class="math inline">\(m_t\)</span>与二阶动量<span
class="math inline">\(v_t\)</span>(或者<span
class="math inline">\(r_t\)</span>)，因此其训练时的显存占用为参数量的4倍。</p>
<h3 id="adam-mini">Adam-mini</h3>
<p>Adam(W)什么都好，但是耗显存，每个参数都需要额外储存的一阶动量<span
class="math inline">\(m\)</span>和二阶动量<span
class="math inline">\(v\)</span>。</p>
<blockquote>
<p>是否有必要对每个参数使用单独的学习率？如果不需要，我们可以节省多少？</p>
</blockquote>
<ul>
<li><strong>目标</strong>：减少内存占用，同时保持优化性能。</li>
<li><strong>方法</strong>：通过减少Adam中的学习率资源来降低内存占用。</li>
<li><strong>原理</strong>：基于Hessian矩阵的结构，将参数分组，并为每个组分配单一但高质量的学习率。</li>
</ul>
<p>贡献：</p>
<ol type="1">
<li><strong>新优化器</strong>：提出了Adam-mini，它通过基于Hessian结构的原则对模型参数进行分组，并为每个块选择单一学习率。</li>
<li><strong>轻量级</strong>：显著减少了Adam中使用的学习能力数量，节省了45%到50%的内存成本。</li>
<li><strong>有效性</strong>：在各种规模的语言模型上，包括预训练、监督微调和强化学习，Adam-mini都显示出与AdamW相当或更好的性能。</li>
<li><strong>高效率</strong>：在预训练Llama2-7B时，Adam-mini比AdamW提高了49.6%的吞吐量，节省了33%的墙钟时间。</li>
</ol>
<h2 id="微调方法">微调方法</h2>
<p>分为全参数微调和参数高效微调。</p>
<h3 id="全参数微调">全参数微调</h3>
<p>这个没啥好说的，就是直接全部参数堆上去微调就行了。优点是理论上限高，微调出来的模型效果好。缺点是显存占用高，容易灾难性遗忘和过拟合。</p>
<h3 id="参数高效微调">参数高效微调</h3>
<p>参考HuggingFace的PEFT设计，介绍LoRA、Prefix Tuning、Prompt
Tuning和P-Tuning。参考知乎文章：大模型参数高效微调(PEFT)（https://zhuanlan.zhihu.com/p/621700272）</p>
<h4 id="peft方法概述">PEFT方法概述</h4>
<p>如下图所示，PEFT 方法可以分为三类，不同的方法对 PLM
的不同部分进行下游任务的适配：</p>
<ul>
<li><strong>Prefix/Prompt-Tuning</strong>：在模型的输入或隐层添加<span
class="math inline">\(k\)</span>个额外可训练的前缀
tokens（这些前缀是连续的伪 tokens，不对应真实的
tokens），只训练这些前缀参数；</li>
<li><strong>Adapter-Tuning</strong>：将较小的神经网络层或模块插入预训练模型的每一层，这些新插入的神经模块称为
adapter（适配器），下游任务微调时也只训练这些适配器参数；</li>
<li><strong>LoRA</strong>：通过学习小参数的低秩矩阵来近似模型权重矩阵<span
class="math inline">\(W\)</span>的参数更新，训练时只优化低秩矩阵参数。</li>
</ul>
<figure>
<img src="/images/v2-390fbfabe5d75638edba174ae850c52c_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
Transformer 结构和最先进的 PEFT 方法
</center>
<h4 id="prefix-tuning">Prefix Tuning</h4>
<p><strong>Prefix-Tuning
在模型输入前添加一个连续的且任务特定的向量序列</strong>（continuous
task-specific
vectors），称之为<strong>前缀（prefix）</strong>。前缀被视为一系列“虚拟
tokens”，但是它由不对应于真实 tokens 的自由参数组成。与更新所有 PLM
参数的全量微调不同，<strong>Prefix-Tuning 固定 PLM
的所有参数，只更新优化特定任务的
prefix</strong>。因此，在生产部署时，只需要存储一个大型 PLM
的副本和一个学习到的特定任务的
prefix，每个下游任务只产生非常小的额外的计算和存储开销。</p>
<figure>
<img src="/images/v2-162a7488d334c00a50697b732721adb4_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>Fine-tuning 更新所有 PLM
参数，并且需要为每个任务存储完整的模型副本。Prefix-tuning 冻结了 PLM
参数并且只优化了 prefix。因此，只需要为每个任务存储特定 prefix，使
Prefix-tuning 模块化且节省存储空间。</p>
<p>如下图所示，以 GPT2 的自回归语言模型为例，将输入<span
class="math inline">\(x\)</span>和输出<span
class="math inline">\(y\)</span>拼接为<span
class="math inline">\(z=[x:y]\)</span>，经过 LM
的某一层计算隐层表示<span class="math inline">\(h=[h_1,\cdots, h_i,
\cdots, h_n]\)</span>，<span
class="math inline">\(h_i=LM_{\phi}(z_i,h_{&lt;i})\)</span>，其中，
<span class="math inline">\(X_{idx}\)</span>和<span
class="math inline">\(Y_{idx}\)</span>分别为输入和输出序列的索引。</p>
<figure>
<img src="/images/v2-366c1b66df31167f70bb1085a1c55003_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>Prefix-Tuning 示例图</p>
<p>Prefix-Tuning 在输入前添加前缀，即<span
class="math inline">\(z=[prefix, x, y]\)</span> ，<span
class="math inline">\(P_{idx}\)</span>为前缀序列的索引， <span
class="math inline">\(|P_{idx}|\)</span>
为前缀的长度。前缀索引对应着由<span
class="math inline">\(\theta\)</span>参数化的向量矩阵<span
class="math inline">\(P_\theta\)</span>，维度为<span
class="math inline">\(|P_{idx}|\times
dim(h_i)\)</span>。隐层表示的计算如下式所示，若索引为前缀索引<span
class="math inline">\(P_{idx}\)</span> ，直接从<span
class="math inline">\(P_\theta\)</span>复制对应的向量作为<span
class="math inline">\(h_i\)</span>（<strong>在模型每一层都添加前缀向量</strong>）；否则直接通过
LM 计算得到，同时，经过 LM 计算的<span
class="math inline">\(h_i\)</span>也依赖于其左侧的前缀参数<span
class="math inline">\(P_\theta\)</span>，即<strong>通过前缀来影响后续的序列隐层激化值</strong>。
<span class="math display">\[
h_i =  \begin{cases}  P_\theta [i,:] &amp; \text{if i} \in
P_{idx}  \\  LM_\phi(z_i, h_{&lt;i})       &amp; \text{
otherwise.}  \end{cases}\\
\]</span> 但是直接优化<span
class="math inline">\(P_\theta\)</span>会导致训练不稳定，通过一个更小的矩阵<span
class="math inline">\(P_\theta
&#39;\)</span>和一个更大的前馈神经网络<span
class="math inline">\(MLP_\theta\)</span>对<span
class="math inline">\(P_\theta\)</span>进行重参数化: <span
class="math inline">\(P_\theta[i,:]=MLP_\theta(P_\theta&#39;[i,:])\)</span>
。在训练时，LM 的参数<span
class="math inline">\(\phi\)</span>被固定，只有前缀参数<span
class="math inline">\(\theta\)</span>为可训练的参数。训练完成后，只有前缀<span
class="math inline">\(P_\theta\)</span>被保存。</p>
<h4 id="p-tuning">P-Tuning</h4>
<p>P-Tuning 的方法思路与 Prefix-Tuning 很相近，P-Tuning 利用少量连续的
embedding 参数作为 prompt <strong>使 GPT 更好的应用于 NLU 任务，而
Prefix-Tuning 是针对 NLG 任务设计</strong>，同时，<strong>P-Tuning 只在
embedding 层增加参数，而 Prefix-Tuning
在每一层都添加可训练参数</strong>。</p>
<p>如下图所示，具体的 NLU 任务以预测一个城市的首都为例，一个离散的
prompt 模板<span class="math inline">\(T\)</span>可以写为："The capital
of Britain is [MASK]."，其中"Britain"为输入的上下文<span
class="math inline">\(x\)</span>，"[MASK]"位置为需要输出的目标<span
class="math inline">\(y\)</span>。而对于连续的 prompt
模板可以表示为：<span class="math inline">\(T=\{
[P_{0:i}],x,[P_{i+1:m}],y \}\)</span>，其中，<span
class="math inline">\([P_i]\)</span> 表示模板<span
class="math inline">\(T\)</span>中<span
class="math inline">\(i^{th}\)</span>个 prompt token，且为伪
token。经过嵌入层将模板<span
class="math inline">\(T\)</span>映射为：<span
class="math inline">\(h_0,\cdots,h_i,e(x),h_{i+1},\cdots,h_m,e(y)\)</span>，其中<span
class="math inline">\(h_i\)</span>为可训练的参数，而其它预训练的真实token向量以及模型权重参数都被固定。</p>
<figure>
<img src="/images/v2-d7db2f86c0b7f81ee35c9947e2e2dff8_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
P-Tuning 示例图
</center>
<p>直接优化连续的 prompt
参数面临两个挑战：一是预训练模型原始的词向量已经高度离散，若随机初始化
prompt 向量并进行 SGD 优化，也只会在小范围内优化并陷入局部最小值；二是
prompt 向量之间是相互关联而不是独立的。论文中<strong>设计了一个 prompt
编码器，该编码器由一个 Bi-LSTM 和一个两层的前馈神经网络组成，对 prompt
embedding 序列进行编码后再传入到语言模型中</strong>。</p>
<figure>
<img src="/images/v2-13cf2807456d259f7d1d3567879bc2bb_720w.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>论文的实验主要表明了：在 SuperGLUE 基准测试中，P-tuning 使得
GPT-style 的生成式模型与相同大小的 BERT 在 NLU
方面实现可比较，有时甚至更好的性能。</p>
<p><strong>P-Tuning V2</strong>方法的思路其实和 Prefix-Tuning
相似，在<strong>模型的每一层都应用连续的 prompts</strong> 并对 prompts
参数进行更新优化。同时，该方法是<strong>针对 NLU
任务优化和适配</strong>的。</p>
<figure>
<img src="/images/v2-427efd6dafc7e89419bad80f70f29332_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
P-Tuning V2 示例图
</center>
<h4 id="prompt-tuning">Prompt Tuning</h4>
<p>Prompt Tuning 方式可以看做是 Prefix Tuning
的简化，<strong>固定整个预训练模型参数，只允许将每个下游任务的额外<span
class="math inline">\(k\)</span>个可更新的 tokens
前置到输入文本中，也没有使用额外的编码层或任务特定的输出层</strong>。如下图所示，在模型大小增加到一定规模时，仅仅使用
Prompt Tuning 就足以达到 Fine Tuning 的性能。</p>
<figure>
<img src="/images/v2-e9cec708078ba2a09c70fba669a8c992_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
T5 的 Model Tuning
实现了强大的性能，但需要为每个任务存储单独的模型副本。
随着模型规模的增加，对 T5 的 Prompt Tuning 与 Model Tuning
的性能相当，同时允许所有任务复用同一固定模型。Prompt Tuning
方法明显优于使用 GPT-3 的少样本 Prompt Design。
</center>
<p>Prompt Tuning 以 T5 为基础，将所有任务转化成文本生成任务，表示为<span
class="math inline">\(Pr_\theta(Y|X)\)</span>。Prompt Tuning 在输入<span
class="math inline">\(X\)</span>前额外添加一系列特殊 tokens <span
class="math inline">\(P\)</span>，输入语言模型生成<span
class="math inline">\(Y\)</span>，即<span
class="math inline">\(Pr_{\theta;\theta_P}(Y|[P;X])\)</span>。其中，<span
class="math inline">\(\theta\)</span>为预训练模型参数，在训练过程被固定，<span
class="math inline">\(\theta_P\)</span>为 prompts
的专有参数，在训练过程被更新优化。通过将输入<span
class="math inline">\(X\)</span>的 embedding 矩阵<span
class="math inline">\(X_e\)</span>与 prompts 的 embedding
矩阵进行拼接<span class="math inline">\([P_e,X_e]\)</span>输入 T5
模型，最大化 $Y的概率训练模型，但是只有 prompt 参数被更新。</p>
<figure>
<img src="/images/v2-c46b3082b5d495de6c8a9aa74f8970a6_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
模型微调需要制作整个预训练模型的任务特定副本，推理分批执行。Prompt
tuning 只需为每个任务存储一个 Task
Prompts，并使用原始预训练模型进行混合任务推理。
</center>
<p><strong>Prompt Tuning 提出了 Prompt Ensembling
方法来集成预训练语言模型的多种
prompts。</strong>通过在同一任务上训练<span
class="math inline">\(N\)</span>个 prompts，为一个任务创建了<span
class="math inline">\(N\)</span>个单独的模型，同时在整个过程中共享核心的预训练语言建模参数。
除了大幅降低存储成本外，提示集成还使推理更加高效。
处理一个样例时，可以执行批此大小为<span
class="math inline">\(N\)</span>的单个前向传递，而不是计算<span
class="math inline">\(N\)</span>次不同模型的前向传递，跨批次复制样例并改变
prompts。在推理时可以使用 major voting 方法从 prompt ensembling
中得到整体的预测。</p>
<h4 id="adapter-tuning">Adapter Tuning</h4>
<p>与 Prefix Tuning 和 Prompt Tuning 这类在输入前可训练添加 prompt
embedding 参数来以少量参数适配下游任务，<strong>Adapter Tuning
则是在预训练模型内部的网络层之间添加新的网络层或模块来适配下游任务</strong>。假设预训练模型函数表示为<span
class="math inline">\(\phi_w(x)\)</span> ，对于 Adapter Tuning
，添加适配器之后模型函数更新为：<span
class="math inline">\(\phi_{w,w_0}(x)\)</span> ，<span
class="math inline">\(w\)</span>是预训练模型的参数， <span
class="math inline">\(w_0\)</span>是新添加的适配器的参数，在训练过程中，
<span class="math inline">\(w\)</span>被固定，只有 <span
class="math inline">\(w_0\)</span>被更新。<span
class="math inline">\(|w_0| \ll |w|\)</span>
，这使得不同下游任务只需要添加少量可训练的参数即可，节省计算和存储开销，同时共享大规模预训练模型。</p>
<p>Adapter 主要包括 Series Adapter（串行） 和 Parallel
Adapter（并行）：</p>
<ul>
<li>Series Adapter的适配器结构和与 Transformer
的集成如下图（a）所示。适<strong>配器模块被添加到每个 Transformer
层两次：多头注意力映射之后和两层前馈神经网络之后</strong>。适配器是一个
bottleneck（瓶颈）结构的模块，由一个两层的前馈神经网络（由向下投影矩阵、非线性函数和向上投影矩阵构成）和一个输出输出之间的残差连接组成。</li>
<li>Parallel Adapter如下图（b）所示。<strong>将适配器模块与每层
Transformer 的多头注意力和前馈层并行计算集成</strong>。</li>
</ul>
<figure>
<img src="/images/v2-33866038c400efe8a8b16dcc72be654c_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4 id="lora">LoRA</h4>
<p>现有的 PEFT 方法主要有两类：Adapter Tuning 和 Prefix
Tuning。<strong>Adapter Tuning 在 PLM
基础上添加适配器层会引入额外的计算，带来推理延迟问题</strong>；而
<strong>Prefix Tuning
难以优化，其性能随可训练参数规模非单调变化，更根本的是，为前缀保留部分序列长度必然会减少用于处理下游任务的序列长度</strong>。</p>
<p><strong>1. 方法原理</strong></p>
<p>给定一个由<span
class="math inline">\(\Phi\)</span>参数化的预训练的自回归语言模型<span
class="math inline">\(P_\Phi(y|x)\)</span>，对于全量微调，模型参数由预训练权重<span
class="math inline">\(\Phi_0\)</span>
初始化，并反复跟随使得条件语言模型目标函数最大化的梯度更新至<span
class="math inline">\(\Phi_0+\Delta \Phi\)</span>。 <span
class="math display">\[
\max_{\Phi} \sum_{(x,y)} \sum_{t=1}^{|y|} \log(P_\Phi(y_t|x,y_{&lt;t}))
\]</span>
全量微调的一个主要缺点就是针对每个下游任务都学习和预训练权重维度相同的全新参数集合<span
class="math inline">\(\Delta \Phi\)</span> ，即<span
class="math inline">\(|\Delta \Phi|=|\Phi_0|\)</span>。尤其是 GPT-3 175B
这类大模型，全量微调对计算和存储资源的消耗是非常大的，存储和部署不同微调模型实例也是不可能的。LoRA
论文提出了一种计算和存储高效的低秩（Low-Rank）表示方法，利用更小规模的参数集合<span
class="math inline">\(\Theta\)</span>来对任务特定的参数增量进行编码，<span
class="math inline">\(\Delta \Phi = \Delta \Phi(\Theta)\)</span>,<span
class="math inline">\(|\Theta| \ll |\Phi_0|\)</span>。利用该方法对 175B
GPT-3 微调，需要训练更新的参数数量<span
class="math inline">\(|\Theta|\)</span>以小到全量微调参数数量<span
class="math inline">\(|\Theta_0|\)</span>的 0.01%。</p>
<p>具体地，Transformer
等神经网络包含许多执行矩阵乘法的密集层，这些权重矩阵通常具有满秩。研究表明预训练的语言模型具有较低的"内在维度（Instrisic
Dimension）"，并且可以和完整参数空间一样进行有效学习。受此启发，假设权重的更新在微调适配过程中也具有较低的"内在秩（Instrisic
Rank）"。对于预训练模型的权重矩阵<span class="math inline">\(W_0 \in
R^{d\times k}\)</span>，通过低秩分解（Low-Rank
Decomposition）来表示约束其更新。 <span class="math display">\[
W_0 + \Delta W = W_0 + BA
\]</span> 其中,<span class="math inline">\(B \in R^{d\times k}, A \in
R^{r\times k}, r \ll min(d,k)\)</span> 。训练过程，<span
class="math inline">\(W_0\)</span>被固定不再进行梯度更新，只训练<span
class="math inline">\(A\)</span>和<span
class="math inline">\(B\)</span>，如下图所示。对于输入<span
class="math inline">\(x\)</span>，模型的前向传播过程<span
class="math inline">\(h=W_0 x\)</span>被更新为： <span
class="math display">\[
h=W_0 x+ BAx
\]</span> <img
src="/images/v2-9f5da4dc36952fc2342015984508a63e_720w.webp"
alt="img" /></p>
<center>
LoRA重参数化示意图，预训练模型的参数W固定，只训练A和B参数
</center>
<p><strong>2. 方法优点</strong></p>
<ul>
<li><strong>全量微调的一般化</strong>：LoRA
不要求权重矩阵的累积梯度更新在适配过程中具有满秩。当对所有权重矩阵应用
LoRA 并训练所有偏差时，将 LoRA 的秩<span
class="math inline">\(r\)</span>设置为预训练权重矩阵的秩，就能大致恢复了全量微调的表现力。也就是说，随着增加可训练参数的数量，训练
LoRA 大致收敛于训练原始模型。</li>
<li><strong>没有额外的推理延时</strong>：在生产部署时，可以明确地计算和存储<span
class="math inline">\(W=W_0 +
BA\)</span>，并正常执行推理。当需要切换到另一个下游任务时，可以通过减去<span
class="math inline">\(BA\)</span>来恢复<span
class="math inline">\(W_0\)</span>，然后增加一个不同的<span
class="math inline">\(B&#39;A&#39;\)</span>，这是一个只需要很少内存开销的快速运算。最重要的是，与结构参数上微调的模型相比，LoRA
推理过程中没有引入任何额外的延迟。</li>
<li><strong>减少内存和存储资源消耗</strong>：对于用 Adam 训练的大型
Transformer，若<span class="math inline">\(r \ll d_{model}\)</span>
，LoRA 减少 2/3 的VRAM 用量（训练模型时，模型参数往往都会存储在显存 VRAM
中），因为不需要存储已固定的预训练参数<span
class="math inline">\(W_0\)</span>的优化器状态，可以用更少的GPU进行大模型训练。在
GPT-3 175B 上，训练期间的 VRAM 消耗从 1.2TB 减少到 350GB。在<span
class="math inline">\(r=4\)</span>且只有query 和 value
矩阵被调整的情况下，checkpoint 的大小大约减少了 10,000 倍（从 350GB 到
35MB）。另一个好处是，可以在部署时以更低的成本切换任务，只需更换 LoRA
的权重，而不是所有的参数。可以创建许多定制的模型，这些模型可以在将预训练的权重存储在
VRAM 中的机器上进行实时切换。在 GPT-3 175B
上训练时，与完全微调相比，速度提高了25%，因为我们不需要为绝大多数的参数计算梯度。</li>
</ul>
<p><strong>3. 实验分析</strong></p>
<p>实验将五种方法进行对比，包括：Fine-Tuning (全量微调)、Bias-only or
BitFit（只训练偏置向量）、Prefix-embedding tuning (PreEmbed，上文介绍的
Prefix Tuning 方法，只优化 embedding 层的激活)、Prefix-layer tuning
(PreLayer，Prefix Tuning
方法，优化模型所有层的激活)<strong>、</strong>Adapter tuning（不同的
Adapter 方法：AdapterH、AdapterL、 AdapterP、 AdapterL 、AdapterD）</p>
<p>实验结果以 LoRA 在 GPT-3 175B
上的验证分析为例。如下表所示，<strong>LoRA
在三个数据集上都能匹配或超过微调基准，证明了 LoRA
方法的有效性</strong>。</p>
<figure>
<img src="/images/v2-f5a9deacddcc837c38e2021faa2a854b_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
GPT-3 上不同适配方法性能。展示了 WikiSQL
上的逻辑形式验证精度，MultiNLI-matched 上的精度，以及SAMSum上 的
Rouge-1/2/L 值。LoRA 比之前的方法表现更好，包括全量微调。在 WikiSQL
上的结果有 ±0.5% 左右的波动，MNLI-m 有 ±0.1% 左右的波动，SAMSum 有
±0.2/±0.2/±0.1 左右的三个指标
</center>
<p>但是，<strong>并不是所有方法都能从拥有更多的可训练参数中获益，而 LoRA
表现出更好的可扩展性和任务性能</strong>。当使用超过256个特殊token进行
Prefix-embedding tuning 或使用超过32个特殊 tokens 进行 Prefix-layer
tuning时，可以观察到性能明显下降。</p>
<figure>
<img src="/images/v2-bee44b20050fb07d80c1e5b9f44559d8_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>GPT-3 175B
准确率与WikiSQL和MNLI匹配的几种适配方法的可训练参数数的关系</p>
<p><strong>[ 应该对 Transformer 中的哪些权重矩阵应用 LoRA ?]</strong>
把所有的参数放在<span class="math inline">\(\Delta W_q\)</span>或<span
class="math inline">\(\Delta
W_k\)</span>中会导致性能明显下降，同时适配<span
class="math inline">\(W_q\)</span>和<span
class="math inline">\(W_v\)</span>会产生最好的结果。这表明，即使<span
class="math inline">\(r=4\)</span>的较小秩也能在<span
class="math inline">\(\Delta
W\)</span>中捕捉到足够的信息，因此，<strong>适配更多的权重矩阵比适配具有较大秩的单一类型的权重矩阵更可取</strong>。</p>
<figure>
<img src="/images/v2-a24e518386cce6b7d185df594bc78860_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
在可训练参数量相同的情况下，将LoRA应用于GPT-3中不同类型的注意力权重后，WikiSQL和MultiNLI的验证准确率
</center>
<p><strong>[ LORA的最佳秩是什么? ]</strong> LoRA 在很小的<span
class="math inline">\(r\)</span>下已经有了很好的表现了（适配<span
class="math inline">\(\{W_q, W_v\}\)</span>比只适配<span
class="math inline">\(W_q\)</span>更有竞争力）。这表明<strong>更新矩阵
<span class="math inline">\(\Delta W\)</span>可能有一个很小的 "intrinsic
rank"，增加秩<span
class="math inline">\(r\)</span>不一定能够覆盖一个更有意义的子空间，一个低秩的适配矩阵已经足够</strong>。</p>
<figure>
<img src="/images/v2-9c4e635e644a0187c4f0c3d8e50b18d0_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
在WikiSQL和MultiNLI上用不同的秩 r 进行验证的准确性
</center>
<p><strong>[适配矩阵<span class="math inline">\(\Delta W\)</span>与<span
class="math inline">\(W\)</span>关系如何？]</strong> 通过计算<span
class="math inline">\(U^TWV^T\)</span>将<span
class="math inline">\(W\)</span>投射到<span class="math inline">\(\Delta
W\)</span>的<span class="math inline">\(r\)</span>维子空间，<span
class="math inline">\(U/V\)</span>是<span class="math inline">\(\Delta
W\)</span>的左/右奇异向量矩阵。然后，比较<span
class="math inline">\(||U^TWV^T||_F\)</span>和<span
class="math inline">\(||W||_F\)</span>之间的 Frobenius
范数。作为比较，还计算了将<span
class="math inline">\(||U^TWV^T||_F\)</span>中<span
class="math inline">\(U\)</span>、<span
class="math inline">\(V\)</span>替换为<span
class="math inline">\(W\)</span>的前<span
class="math inline">\(r\)</span>个奇异向量或一个随机矩阵。</p>
<ul>
<li>与随机矩阵相比，<span class="math inline">\(\Delta W\)</span>与<span
class="math inline">\(W\)</span>有更强的相关性，表明<span
class="math inline">\(\Delta W\)</span>放大了<span
class="math inline">\(W\)</span>中已有的一些特征；</li>
<li><span class="math inline">\(\Delta W\)</span>没有重复<span
class="math inline">\(W\)</span>的顶级奇异方向，而只是放大了<span
class="math inline">\(W\)</span>中没有强调的方向；</li>
<li><strong>低秩适配矩阵可能会放大特定下游任务的重要特征，而这些特征在一般的预训练模型中没有得到强调</strong>。</li>
</ul>
<figure>
<img src="/images/v2-2467d9f8377857eb78185a6647967fe3_720w.webp"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<center>
不同秩下 Frobenius范数
</center>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://lisheng2001.github.io">LiSheng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://lisheng2001.github.io/2024/09/24/NLP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%A8-1/">https://lisheng2001.github.io/2024/09/24/NLP基础知识补全-1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://lisheng2001.github.io" target="_blank">一世逍遥的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a><a class="post-meta__tags" href="/tags/NLP/">NLP</a></div><div class="post_share"><div class="social-share" data-image="/images/avatar.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/01/04/word%E7%BC%BA%E5%A4%B1%E5%AD%97%E4%BD%93%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" title="word缺失字体的解决方案"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">word缺失字体的解决方案</div></div></a></div><div class="next-post pull-right"><a href="/2024/09/19/%E7%94%B0%E5%BF%8C%E8%B5%9B%E9%A9%AC%E9%97%AE%E9%A2%98/" title="田忌赛马问题"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">田忌赛马问题</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/10/14/%E6%9C%9D%E8%8A%B1%E5%A4%95%E6%8B%BE%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94Transformer/" title="朝花夕拾（一）——Transformer"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-14</div><div class="title">朝花夕拾（一）——Transformer</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="utterances-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/avatar.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">LiSheng</div><div class="author-info__description">也无风雨也无晴</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">51</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">71</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/LiSheng2001"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#nlp%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%A8"><span class="toc-number">1.</span> <span class="toc-text">NLP基础知识补全</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.</span> <span class="toc-text">损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.1.</span> <span class="toc-text">1. 什么是损失函数？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.2.</span> <span class="toc-text">2. 为什么使用损失函数？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%89%E5%93%AA%E4%BA%9B%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.3.</span> <span class="toc-text">3. 有哪些损失函数？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">3.1 基于距离度量的损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0mse"><span class="toc-number">1.1.3.1.1.</span> <span class="toc-text">3.1.1 均方误差损失函数（MSE）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#l2%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.3.1.2.</span> <span class="toc-text">3.1.2 L2损失函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#l1%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.3.1.3.</span> <span class="toc-text">3.1.3 L1损失函数</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E5%BA%A6%E9%87%8F%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">3.2 基于概率分布度量的损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#kl%E6%95%A3%E5%BA%A6%E5%87%BD%E6%95%B0%E7%9B%B8%E5%AF%B9%E7%86%B5"><span class="toc-number">1.1.3.2.1.</span> <span class="toc-text">3.2.1 KL散度函数（相对熵）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.1.3.2.2.</span> <span class="toc-text">3.2.2 交叉熵损失</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#softmax%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.3.2.3.</span> <span class="toc-text">3.2.3 softmax损失函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#focal-loss"><span class="toc-number">1.1.3.2.4.</span> <span class="toc-text">3.2.4 Focal loss</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.4.</span> <span class="toc-text">4. 如何选择损失函数？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">1.2.</span> <span class="toc-text">优化器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="toc-number">1.2.1.</span> <span class="toc-text">梯度下降法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%95%B0%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87"><span class="toc-number">1.2.2.</span> <span class="toc-text">指数移动平均</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E9%87%8F%E6%B3%95momentum"><span class="toc-number">1.2.3.</span> <span class="toc-text">动量法(Momentum)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#adagrad"><span class="toc-number">1.2.4.</span> <span class="toc-text">AdaGrad</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rmsprop"><span class="toc-number">1.2.5.</span> <span class="toc-text">RMSprop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#adam"><span class="toc-number">1.2.6.</span> <span class="toc-text">Adam</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#adamw"><span class="toc-number">1.2.7.</span> <span class="toc-text">AdamW</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#adam-mini"><span class="toc-number">1.2.8.</span> <span class="toc-text">Adam-mini</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95"><span class="toc-number">1.3.</span> <span class="toc-text">微调方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83"><span class="toc-number">1.3.1.</span> <span class="toc-text">全参数微调</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83"><span class="toc-number">1.3.2.</span> <span class="toc-text">参数高效微调</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#peft%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">PEFT方法概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#prefix-tuning"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">Prefix Tuning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#p-tuning"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">P-Tuning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#prompt-tuning"><span class="toc-number">1.3.2.4.</span> <span class="toc-text">Prompt Tuning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#adapter-tuning"><span class="toc-number">1.3.2.5.</span> <span class="toc-text">Adapter Tuning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#lora"><span class="toc-number">1.3.2.6.</span> <span class="toc-text">LoRA</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/28/%E4%BB%8E3%E7%AF%87%E8%AE%BA%E6%96%87%E5%9B%9E%E9%A1%BE2024%E5%B9%B4%E5%9F%BA%E7%A1%80%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%9B%E5%B1%95/" title="从3篇论文回顾2024年基础大语言模型的进展">从3篇论文回顾2024年基础大语言模型的进展</a><time datetime="2025-03-28T13:03:49.000Z" title="发表于 2025-03-28 21:03:49">2025-03-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/27/%E8%AF%84%E4%BC%B0LLM%E4%B9%8B%E5%9C%A824%E5%B9%B4%E7%9A%84%E7%AE%A1%E7%90%86%E7%B1%BB%E8%81%94%E8%80%83%E9%80%BB%E8%BE%91%E9%80%89%E6%8B%A9%E9%A2%98%E8%AF%84%E4%BC%B0/" title="评估LLM之在24年的管理类联考逻辑选择题评估">评估LLM之在24年的管理类联考逻辑选择题评估</a><time datetime="2025-01-27T08:33:07.000Z" title="发表于 2025-01-27 16:33:07">2025-01-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/23/%E5%9C%A8hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E6%8F%92%E5%85%A5echarts%E5%9B%BE%E8%A1%A8/" title="在hexo博客中插入echarts图表">在hexo博客中插入echarts图表</a><time datetime="2025-01-23T03:59:36.000Z" title="发表于 2025-01-23 11:59:36">2025-01-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/06/huggingface%E4%B8%ADDatasets%E6%A8%A1%E5%9D%97%E7%9A%84%E7%AC%94%E8%AE%B0/" title="huggingface中Datasets模块的笔记">huggingface中Datasets模块的笔记</a><time datetime="2025-01-06T12:43:34.000Z" title="发表于 2025-01-06 20:43:34">2025-01-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/04/LLM%E8%AF%84%E4%BC%B0/" title="LLM评估">LLM评估</a><time datetime="2025-01-04T12:45:23.000Z" title="发表于 2025-01-04 20:45:23">2025-01-04</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By LiSheng</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script>function runPanguForPostContent() {
  const postContent = document.querySelector('.post-content');

  if (postContent) {
    pangu.spacingNode(postContent); // 只处理文章内容区域
  }
}

function panguFn() {
  if (typeof pangu === 'object') {
    runPanguForPostContent();
  } else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        runPanguForPostContent();
      });
  }
}

function panguInit() {
  if (false) {
    GLOBAL_CONFIG_SITE.isPost && panguFn();
  } else {
    panguFn();
  }
}

document.addEventListener('DOMContentLoaded', panguInit);</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
  }

  btf.addModeChange('mermaid', runMermaid)

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>function loadUtterances () {
  let ele = document.createElement('script')
  ele.setAttribute('id', 'utterances_comment')
  ele.setAttribute('src', 'https://utteranc.es/client.js')
  ele.setAttribute('repo', 'LiSheng2001/LiSheng2001.github.io')
  ele.setAttribute('issue-term', 'pathname')
  let nowTheme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'photon-dark' : 'github-light'
  ele.setAttribute('theme', nowTheme)
  ele.setAttribute('crossorigin', 'anonymous')
  ele.setAttribute('async', 'true')
  document.getElementById('utterances-wrap').insertAdjacentElement('afterbegin',ele)
}

function utterancesTheme (theme) {
  const iframe = document.querySelector('.utterances-frame')
  if (iframe) {
    const theme = theme === 'dark' ? 'photon-dark' : 'github-light'
    const message = {
      type: 'set-theme',
      theme: theme
    };
    iframe.contentWindow.postMessage(message, 'https://utteranc.es');
  }
}

btf.addModeChange('utterances', utterancesTheme)

if ('Utterances' === 'Utterances' || !true) {
  if (true) btf.loadComment(document.getElementById('utterances-wrap'), loadUtterances)
  else loadUtterances()
} else {
  function loadOtherComment () {
    loadUtterances()
  }
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>